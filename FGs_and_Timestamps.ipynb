{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RIKER 1.0.0 - Facial Data is imported (after having been processed by OpenFace with -aus flag),\n",
    "# and data is temporally segmented to identify the start, end, and peak of individual \n",
    "# Facial Action units. Then, individual actions are aggregated together into a DataFrame,\n",
    "# Then, the aggregated actions are clustered together (using DBSCAN algorithm)\n",
    "# into Facial Gestures, and the FGs are filtered (very minor gestures are removed).\n",
    "# Lastly, timestamp information is loaded in from the .log file, and FGs are matched up with the\n",
    "# trimmed to include only FGs that ocurred during the poker game (those that ocurred before and \n",
    "# after are discarded), and the FGs are given new timestamps relative to the beginning\n",
    "# of the poker game.\n",
    "\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "# import datetime\n",
    "import warnings\n",
    "\n",
    "#from ipynb.fs.full.Game_State_Parser import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pp\n",
    "# import seaborn\n",
    "# from collections import deque\n",
    "\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import cycle, islice, chain\n",
    "# from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads a log file of time stamps that indicate when the PokerTH log file was modified (i.e. when an action was taken in the game).\n",
    "def get_timestamps(ts_filename_):\n",
    "\n",
    "    timestamps = []\n",
    "\n",
    "    with open(ts_filename_) as f:\n",
    "        for line in f:\n",
    "            if \"Modified file\" in line:\n",
    "                for word in line.split():\n",
    "                    if \",\" in word:\n",
    "                        #print(word)\n",
    "                        timestamps.append(word)\n",
    "                        \n",
    "        #Extra lines added for overflow in timestamps matching with PokerActs later...\n",
    "        timestamps.append(\"00:00:00,000\")\n",
    "        timestamps.append(\"00:00:00,000\")\n",
    "        timestamps.append(\"00:00:00,000\")\n",
    "        timestamps.append(\"00:00:00,000\")\n",
    "\n",
    "    return(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads in the data from a .csv file as output by OpenFace FeatureExtraction with the '-aus' flag on.\n",
    "def parse_csv(filename):\n",
    "    load_cols = [0] + [i for i in range (2,22)]                              #which columns we want to use\n",
    "    load_names = ['frame','timestamp','confidence','success','AU01','AU02',  #names of the columns\n",
    "            'AU04','AU05','AU06','AU07','AU09','AU10','AU12','AU14',        \n",
    "            'AU15','AU17','AU20','AU23','AU25','AU26','AU45']\n",
    "    load_types = [np.int32,np.float16,np.float32,np.int32] + [np.float32]*17 #types of the columns\n",
    "\n",
    "    load_file = np.genfromtxt(fname = filename,\n",
    "                  usecols = load_cols,\n",
    "                  dtype = load_types,\n",
    "                  skip_header = 1,\n",
    "                  delimiter = ',',\n",
    "                  names = load_names)\n",
    "    return load_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raw_data(rawdata):\n",
    "    pp.figure(figsize=(25,10))\n",
    "\n",
    "    pp.plot(rawdata['frame'],rawdata['AU01'])#, label='AU01')\n",
    "    pp.plot(rawdata['frame'],rawdata['AU02'])#, label='AU02')\n",
    "    pp.plot(rawdata['frame'],rawdata['AU04'])#, label='AU04')\n",
    "    pp.plot(rawdata['frame'],rawdata['AU05'])#, label='AU05')\n",
    "    pp.plot(rawdata['frame'],rawdata['AU06'])\n",
    "    pp.plot(rawdata['frame'],rawdata['AU07'])#, label='AU07')\n",
    "    pp.plot(rawdata['frame'],rawdata['AU09'])\n",
    "    pp.plot(rawdata['frame'],rawdata['AU10'])\n",
    "    pp.plot(rawdata['frame'],rawdata['AU12'])\n",
    "    pp.plot(rawdata['frame'],rawdata['AU14'])\n",
    "    pp.plot(rawdata['frame'],rawdata['AU15'])\n",
    "    pp.plot(rawdata['frame'],rawdata['AU17'])\n",
    "    pp.plot(rawdata['frame'],rawdata['AU20'])#, label='AU20')\n",
    "    pp.plot(rawdata['frame'],rawdata['AU23'])\n",
    "    pp.plot(rawdata['frame'],rawdata['AU25'])\n",
    "    pp.plot(rawdata['frame'],rawdata['AU26'])#, label='AU26')\n",
    "    pp.plot(rawdata['frame'],rawdata['AU45'])\n",
    "    pp.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_smoothed(t, win=5):\n",
    "    AU01 = np.correlate(t['AU01'],np.ones(win)/win,'same')\n",
    "    AU02 = np.correlate(t['AU02'],np.ones(win)/win,'same')\n",
    "    AU04 = np.correlate(t['AU04'],np.ones(win)/win,'same')\n",
    "    AU05 = np.correlate(t['AU05'],np.ones(win)/win,'same')\n",
    "    AU06 = np.correlate(t['AU06'],np.ones(win)/win,'same')\n",
    "    AU07 = np.correlate(t['AU07'],np.ones(win)/win,'same')\n",
    "    AU09 = np.correlate(t['AU09'],np.ones(win)/win,'same')\n",
    "    AU10 = np.correlate(t['AU10'],np.ones(win)/win,'same')\n",
    "    AU12 = np.correlate(t['AU12'],np.ones(win)/win,'same')\n",
    "    AU14 = np.correlate(t['AU14'],np.ones(win)/win,'same')\n",
    "    AU15 = np.correlate(t['AU15'],np.ones(win)/win,'same')\n",
    "    AU17 = np.correlate(t['AU17'],np.ones(win)/win,'same')\n",
    "    AU20 = np.correlate(t['AU20'],np.ones(win)/win,'same')\n",
    "    AU23 = np.correlate(t['AU23'],np.ones(win)/win,'same')\n",
    "    AU25 = np.correlate(t['AU25'],np.ones(win)/win,'same')\n",
    "    AU26 = np.correlate(t['AU26'],np.ones(win)/win,'same')\n",
    "    AU45 = np.correlate(t['AU45'],np.ones(win)/win,'same')\n",
    "    \n",
    "    smoothedAUs = np.vstack((AU01, AU02, AU04, AU05, AU06, AU07, AU09, AU10, AU12, AU14, AU15, AU17, AU20, AU23, AU25, AU26, AU45))\n",
    "    \n",
    "    return(smoothedAUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def au_detect(action_unit,label):\n",
    "    # ***COMMENT NEEDS UPDATE***An array containing codes for noting when gestures started(1), peaked(2), and ended(3) during the sequence, as\n",
    "    # well as the amplitude for the that gesture (encoded as the amplitude change from start to peak), and the \n",
    "    # duration of the gesture (encoded as the distance between the start and the end indices).\n",
    "    \n",
    "    au_data = np.array([0,0,0,0,0]).reshape((1,5))\n",
    "    au_df = pd.DataFrame(au_data, columns=list('SPEBT'))\n",
    "    au_df['AU Label'] = [label]\n",
    "    #print(au_df)\n",
    "    \n",
    "    begun = False\n",
    "    rising = False\n",
    "    peaked = False\n",
    "    ending = False\n",
    "    sensitivity = 0.07\n",
    "    start_index = 0\n",
    "    start_amp = 0\n",
    "    peak_index = 0\n",
    "    peak_amp = 0\n",
    "    \n",
    "    \n",
    "    for i in range(len(action_unit)):\n",
    "        if i > 1:\n",
    "            if action_unit[i] - action_unit[i-2] >= sensitivity and rising == False:\n",
    "                rising = True\n",
    "                begun = True\n",
    "                output = \"Started a gesture at \" + repr(i)\n",
    "                start_amp = action_unit[i-2]\n",
    "                next_au = np.array([start_index,peak_index,i-1,start_amp,peak_amp]).reshape((1,5))\n",
    "                next_au_df = pd.DataFrame(next_au, columns=list('SPEBT'))\n",
    "                next_au_df['AU Label'] = [label]\n",
    "                new_list = au_df, next_au_df\n",
    "                au_df = pd.concat(new_list)\n",
    "                start_index = i\n",
    "                peak_index = 0\n",
    "            elif action_unit[i] - action_unit[i-2] >= sensitivity and rising == True:\n",
    "                output = \"Kept going up at \" + repr(i)\n",
    "            elif action_unit[i] + action_unit[i-1] < sensitivity and rising == False and ending == False:\n",
    "                output = \"Still at baseline at \" +repr(i)\n",
    "            elif action_unit[i] - action_unit[i-1] <= sensitivity and rising == True:\n",
    "                rising = False\n",
    "                peaked = True\n",
    "                ending = False\n",
    "                output = \"Peaked at \" + repr(i)\n",
    "                peak_index = i\n",
    "                peak_amp = action_unit[i-1]\n",
    "            elif action_unit[i] - action_unit[i-2] <= (0 - sensitivity) and rising == False and peaked == True:\n",
    "                rising = False\n",
    "                peaked = True\n",
    "                ending = True\n",
    "                output = \"Coming down at \" + repr(i-1)\n",
    "            elif action_unit[i] - action_unit[i-2] < sensitivity and ending == True and action_unit[i] > sensitivity:\n",
    "                output = \"Held steady for now at \" + repr(i-1)\n",
    "            elif action_unit[i] - action_unit[i-2] < sensitivity and ending == True and action_unit[i] < sensitivity:\n",
    "                begun = False\n",
    "                rising = False\n",
    "                peaked = False\n",
    "                ending = False\n",
    "                output = \"Back to baseline at \" + repr(i)\n",
    "                next_au = np.array([start_index,peak_index,i-1,start_amp,peak_amp]).reshape((1,5))\n",
    "                next_au_df = pd.DataFrame(next_au, columns=list('SPEBT'))\n",
    "                next_au_df['AU Label'] = [label]\n",
    "                new_list = au_df, next_au_df\n",
    "                au_df = pd.concat(new_list)\n",
    "                start_index = i\n",
    "                peak_index = i\n",
    "                peak_amp = 0\n",
    "                     \n",
    "    return(au_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the facial actions into a single dataframe.\n",
    "def aggregate_actions(smoothed_actions):\n",
    "    AU_labels = ['01','02','04','05','06','07','09','10','12','14','15','17','20','23','25','26','45']\n",
    "\n",
    "    action_data = np.array([0,0,0,0,0]).reshape((1,5))\n",
    "    action_df = pd.DataFrame(action_data, columns = ['S','P','E','B','T']) #Start Time, Peak Time, End Time, Bottom Amp, Top Amp\n",
    "    action_df['AU Label'] = [0]\n",
    "    action_df['Index'] = 0\n",
    "\n",
    "    for i in range(len(smoothed_actions)):\n",
    "        all_actions = au_detect(smoothed_actions[i],AU_labels[i])\n",
    "        new_list = action_df, all_actions\n",
    "        action_df = pd.concat(new_list)\n",
    "    \n",
    "    #Remove actions which End at frame 0.\n",
    "    action_df = action_df[action_df.E != 0]\n",
    "    \n",
    "    #Add the index column\n",
    "    index_list = list(range(0,len(action_df['Index'])))\n",
    "    for i in range(len(action_df['Index'])):\n",
    "        action_df.iloc[i,3:4] = index_list[i]\n",
    "    action_df.set_index('Index',inplace=True)\n",
    "    \n",
    "    #Add the TotalAmp column\n",
    "    action_df['TotalAmp'] = 0\n",
    "\n",
    "    for i in range(len(action_df)):\n",
    "        float_index = float(i)\n",
    "        action_df.iloc[i,6:7] = action_df.at[float_index,'T'] - action_df.at[float_index,'B']\n",
    "        \n",
    "    #Add a column containing the timing of the Peak in seconds\n",
    "    action_df['Inflection'] = 0\n",
    "    for i in range(len(action_df)):\n",
    "        float_index = float(i)\n",
    "        inflection_point = (action_df.at[float_index,'P'])\n",
    "        action_df.iloc[i,7:8] = inflection_point/30\n",
    "        \n",
    "    #Add a column containing the duration of action onset\n",
    "    action_df['Onset Frame Count'] = 0\n",
    "    for i in range(len(action_df)):\n",
    "        float_index = float(i)\n",
    "        onset_length = (action_df.at[float_index,'P'])-(action_df.at[float_index,'S'])\n",
    "        action_df.iloc[i,8:9] = onset_length\n",
    "    \n",
    "    #Add a column containing the duration of the action offset\n",
    "    action_df['Offset Frame Count'] = 0\n",
    "    for i in range(len(action_df)):\n",
    "        float_index = float(i)\n",
    "        offset_length = (action_df.at[float_index,'E'])-(action_df.at[float_index,'P'])\n",
    "        action_df.iloc[i,9:10] = offset_length\n",
    "    \n",
    "    #Drop the actions with a TotalAmp < 0\n",
    "    action_df['Drop'] = 0\n",
    "    for i in range(len(action_df)):\n",
    "        float_index = float(i)\n",
    "        if action_df.at[float_index,'TotalAmp'] < 0.01:\n",
    "            action_df.at[float_index,'Drop'] = 1\n",
    "    action_df = action_df[action_df.Drop != 1]\n",
    "    \n",
    "    #Sort by peaks of data\n",
    "    peaks_sort = action_df.sort_values(['P','AU Label'], ascending=[True,True])\n",
    "    \n",
    "    return(peaks_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adds the Gesture label to a dataframe of facial actions, so we can tell which gesture each action belongs to.\n",
    "def add_gestures(actions_df,gesture_group_labels):\n",
    "    actions_df['Gesture'] = 0\n",
    "\n",
    "    for i in range(len(gesture_group_labels)):\n",
    "        actions_df.iloc[i,11:12] = gesture_group_labels[i]\n",
    "\n",
    "    return(actions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a dataframe of gestures which is built from a dataframe of actions.\n",
    "def actions_to_gestures(actions_df_in,n_action_clusters_in):\n",
    "    #Setting up new dataframe to receive FGs and metadata\n",
    "    all_gestures_df = pd.DataFrame(index=range(0,n_action_clusters_in), columns = ['01','02','04','05','06','07','09','10','12','14','15','17','20','23','25','26','45'], dtype='float')\n",
    "    all_gestures_df['Inflection'] = 0\n",
    "    all_gestures_df['Onset Length'] = 0 #Mean number of frames of action onsets\n",
    "    all_gestures_df['Onset Unity'] = 0 #Variance in frames of action onsets\n",
    "    all_gestures_df['Offset Length'] = 0 #Mean number of rames of action offsets\n",
    "    all_gestures_df['Offset Unity'] = 0 #Variance in frames of action offsets\n",
    "\n",
    "    # For each Gesture\n",
    "    for i in range(n_action_clusters_in):     \n",
    "        gesture_df = actions_df_in[actions_df_in.Gesture == i].set_index('AU Label')\n",
    "\n",
    "        #Add the mean inflection point(peak point) for the gesture to the df\n",
    "        inflection_point = gesture_df['Inflection'].mean()\n",
    "        #print(\"Inflection point is \" + repr(inflection_point))\n",
    "        all_gestures_df.iloc[i,17:18] = inflection_point\n",
    "        \n",
    "        #Add the onset length\n",
    "        onset_length = gesture_df['Onset Frame Count'].mean()\n",
    "        all_gestures_df.iloc[i,18:19] = onset_length\n",
    "        \n",
    "        #Add the onset unity\n",
    "        onset_unity = gesture_df['Onset Frame Count'].var()\n",
    "        all_gestures_df.iloc[i,19:20] = onset_unity\n",
    "        \n",
    "        #Add the offset length\n",
    "        offset_length = gesture_df['Offset Frame Count'].mean()\n",
    "        all_gestures_df.iloc[i,20:21] = offset_length\n",
    "        \n",
    "        #Add the onset unity\n",
    "        offset_unity = gesture_df['Offset Frame Count'].var()\n",
    "        all_gestures_df.iloc[i,21:22] = offset_unity\n",
    "        \n",
    "        #For each action unit observed\n",
    "        for j in range(len(gesture_df)):\n",
    "            #For each column in all_gestures_df, except 'Inflection'\n",
    "            for k in range(len(all_gestures_df.columns)-1): \n",
    "                pos = k\n",
    "                colname = all_gestures_df.columns[pos]\n",
    "                if colname in gesture_df.index:\n",
    "                    all_gestures_df.at[i,colname] = gesture_df.iloc[0,5:6]\n",
    "            if len(gesture_df) > 1:\n",
    "                gesture_df = gesture_df.iloc[1:]\n",
    "    \n",
    "    #Fill in missing values with 0s\n",
    "    all_gestures_filled = all_gestures_df.fillna(0)    \n",
    "    \n",
    "    #Total Amp of all Actions in the Gesture\n",
    "    all_gestures_filled['SumAmp'] = all_gestures_filled.sum(axis=1)\n",
    "    \n",
    "    #Fix the SumpAmp so it doesn't include the Inflection Point (and other metadata) in the sum\n",
    "    for i in range(len(all_gestures_filled)):\n",
    "        all_gestures_filled.iloc[i,22:23] = all_gestures_filled.iat[i,22] - all_gestures_filled.iat[i,21] - all_gestures_filled.iat[i,20] - all_gestures_filled.iat[i,19] - all_gestures_filled.iat[i,18] - all_gestures_filled.iat[i,17]\n",
    "\n",
    "    return(all_gestures_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes gestures from a gestures dataframe which have very small amplitudes.\n",
    "def gesture_filter_low(gestures_df):\n",
    "    gestures_df['Drop'] = 0\n",
    "    \n",
    "    # Identify which gestures have SumAmps < 0.2...\n",
    "    for i in range(len(gestures_df)):\n",
    "        if gestures_df.at[i,'SumAmp'] < 0.2:\n",
    "            gestures_df.iloc[i,23:24] = 1\n",
    "    \n",
    "    # ...and drop them.\n",
    "    gestures_df = gestures_df[gestures_df.Drop != 1]\n",
    "    \n",
    "    #Reset the Index so it is still continuous\n",
    "    gestures_df.reset_index(inplace=True)\n",
    "    gestures_df = gestures_df.loc[:,'01':'SumAmp']\n",
    "\n",
    "    return(gestures_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifies the AUs that start and peak at similar times, and clusters them together.\n",
    "def DBSCAN_propagate(all_smoothed_AUs):\n",
    "    \n",
    "    # Gather all the Facial Actions into a single dataframe, sort that data frame by when the actions\n",
    "    # peak in amplitude.\n",
    "    sort_by_peaks = aggregate_actions(all_smoothed_AUs)\n",
    "    peaks_sort = sort_by_peaks.sort_values(['P','AU Label'], ascending=[True,True])\n",
    "    \n",
    "    #Only count actions with a peak amplitude of greater than 0. \n",
    "    X = peaks_sort.loc[peaks_sort['P']>=0.0,['P','S']].values\n",
    "    \n",
    "    # Compute DBSCAN\n",
    "    clustering = DBSCAN(eps=6.7, min_samples=2, n_jobs=-1).fit(X)\n",
    "    cluster_centers_indices = clustering.core_sample_indices_\n",
    "    labels = clustering.labels_\n",
    "    n_clusters_ = len(cluster_centers_indices)\n",
    "    \n",
    "    # Plot clusters: UNCOMMENT THE FOLLOWING LINES UNTIL THE 'RETURN' LINE\n",
    "    # IN ORDER TO GET A VISUAL GRAPHIC OF THE CLUSTERS. NOTE: THIS GRAPHIC\n",
    "    # WILL LIKELY NOT BE VERY USEFUL FOR MORE THAN A FEW HUNDRED FRAMES OF\n",
    "    # SUBJECT DATA – ANYTHING LONGER THAN THAT WILL JUST APPEAR TOO SMALL.\n",
    "    # THIS IS BEST USED TO VALIDATE THAT THE FUNCTION IS WORKING PROPERLY\n",
    "    # ON A SMALL/SHORT EXAMPLE DATASET.\n",
    "    \n",
    "#     core_samples_mask = np.zeros_like(clustering.labels_, dtype=bool)\n",
    "#     core_samples_mask[clustering.core_sample_indices_] = True\n",
    "    \n",
    "    \n",
    "#     pp.close('all')\n",
    "#     pp.figure(figsize=(13,12))\n",
    "#    # Black removed and is used for noise instead.\n",
    "#     unique_labels = set(labels)\n",
    "#     colors = [pp.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
    "#     for k, col in zip(unique_labels, colors):\n",
    "#         if k == -1:\n",
    "#             # Black used for noise.\n",
    "#             col = [0, 0, 0, 1]\n",
    "\n",
    "#         class_member_mask = (labels == k)\n",
    "\n",
    "#         xy = X[class_member_mask & core_samples_mask]\n",
    "#         pp.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "#                  markeredgecolor='k', markersize=3)\n",
    "\n",
    "#         xy = X[class_member_mask & ~core_samples_mask]\n",
    "#         pp.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "#                  markeredgecolor='k', markersize=1)\n",
    "\n",
    "#     pp.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "#     pp.show()\n",
    "    \n",
    "    return(labels,n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_FGs(subject_num_):\n",
    "    raw_data = parse_csv(str(subject_num_) + '_FaceOnly.csv')\n",
    "    # #plot_raw_data(raw_data)\n",
    "    print(\"Data is imported\")\n",
    "    all_AUs_smoothed = data_smoothed(raw_data)\n",
    "    print(\"Data is smoothed\")\n",
    "    actions_df = aggregate_actions(all_AUs_smoothed)\n",
    "    print(\"Actions are aggregated into dataframe\")\n",
    "    # #print(actions_df)\n",
    "    gesture_group_labels, n_clusters = DBSCAN_propagate(all_AUs_smoothed)\n",
    "    # gesture_group_labels\n",
    "    print(\"Gestures/clusters are identified\")\n",
    "#     print(\"GESTURE GROUP LABELS ARE okay\")\n",
    "#     # #print(gesture_group_labels)\n",
    "#     print(\"n_clusters is okay\")\n",
    "    # #print(n_clusters)\n",
    "    act_with_gest = add_gestures(actions_df,gesture_group_labels)\n",
    "    print(\"And actions have gesture labels.\")\n",
    "    # #print(act_with_gest)\n",
    "    gestures_df = actions_to_gestures(act_with_gest,n_clusters)\n",
    "    print(\"Gestures are in a data frame.\")\n",
    "    # #print(gestures_df)\n",
    "    filtered_gestures_ = gesture_filter_low(gestures_df)\n",
    "    print(\"Gestures are low-pass filtered.\")\n",
    "    \n",
    "    return(filtered_gestures_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_gestures_to_game(filtered_gestures_, times_, rec_start_time_):\n",
    "    print(\"Trimming to fit game start and end time stamps.\")\n",
    "    game_start_time = datetime.strptime(times_[0], \"%H:%M:%S,%f\")\n",
    "    game_end_time = datetime.strptime(times_[-6], \"%H:%M:%S,%f\")\n",
    "\n",
    "    start_diff = game_start_time - rec_start_time_\n",
    "    end_diff = game_end_time - rec_start_time_\n",
    "    secs = start_diff.seconds\n",
    "    mils = start_diff.microseconds\n",
    "    end_secs = end_diff.seconds\n",
    "    end_mils = end_diff.microseconds\n",
    "\n",
    "    relative_start = float(secs+(mils/1000000))\n",
    "    relative_end = float(end_secs + (end_mils/1000000))\n",
    "\n",
    "    game_gests_ = filtered_gestures_.loc[filtered_gestures_['Inflection'] > relative_start]\n",
    "    game_gests_ = game_gests_.loc[filtered_gestures_['Inflection'] < (relative_end + 10)]\n",
    "    # game_gests = \n",
    "    game_gests_['TrueInflection'] = 0\n",
    "    for i in range(0,len(game_gests_)):\n",
    "        game_gests_.iloc[i,-1] = game_start_time + timedelta(seconds = (game_gests_.iloc[i,-7]-relative_start))\n",
    "        \n",
    "    return(game_gests_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING SUBJECT NUMBER 1\n",
      "Data is imported\n",
      "Data is smoothed\n",
      "Actions are aggregated into dataframe\n",
      "Gestures/clusters identified\n",
      "And actions have gesture labels.\n",
      "Gestures are in a data frame.\n",
      "Gestures are low-pass filtered.\n"
     ]
    }
   ],
   "source": [
    "#Main execution of program components\n",
    "\n",
    "#Subject-by-subject metadata, including \"subject number\" and start time of their game.\n",
    "subject_map = pd.read_csv('subject_map.csv')\n",
    "\n",
    "# For each subject on which we have data – with example of just subject 1,\n",
    "# keep this in range 1,2.\n",
    "for subject_num in range(1,2):\n",
    "    print(\"STARTING SUBJECT NUMBER \" + repr(subject_num))\n",
    "    \n",
    "    # Calculate Facial Gestures (FGs) from facial data as processed by OpenFace.\n",
    "    filtered_gestures = get_FGs(subject_num)\n",
    "    \n",
    "    #Get time stamps from subject log\n",
    "    ts_filename = str(subject_num) + \"_timestamps.log\"\n",
    "    times = get_timestamps(ts_filename)\n",
    "    rec_start_time = datetime.strptime(subject_map.iloc[subject_num-1,1], \"%H:%M:%S,%f\")\n",
    "    \n",
    "    # Trim FGs to be FGs that ocurred during the poker game\n",
    "    game_gests = trim_gestures_to_game(filtered_gestures, times, rec_start_time)\n",
    "\n",
    "    #UNCOMMENT THIS NEXT LINE TO OUTPUT THE RESULTS TO THE NEXT PHASE\n",
    "    game_gests.to_csv(str(subject_num)+ \"TEST_FGs_withcorrecttimestamps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
